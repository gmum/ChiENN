{
    "layers_dict":
    {
      "EConv_mlp_hidden_sizes":   [64],
      "GAT_hidden_node_sizes":    [32, 32],

      "encoder_hidden_sizes_D":   [128, 128],
      "encoder_hidden_sizes_phi": [128, 128],
      "encoder_hidden_sizes_c": [128, 128],
      "encoder_hidden_sizes_alpha": [128, 128],

      "encoder_hidden_sizes_sinusoidal_shift": [256, 256],
      "output_mlp_hidden_sizes": [64, 64]
    },


    "activation_dict":
   {
        "encoder_hidden_activation_D": "torch.nn.LeakyReLU(negative_slope=0.01)",
        "encoder_hidden_activation_phi": "torch.nn.LeakyReLU(negative_slope=0.01)",
        "encoder_hidden_activation_c": "torch.nn.LeakyReLU(negative_slope=0.01)",
        "encoder_hidden_activation_alpha": "torch.nn.LeakyReLU(negative_slope=0.01)",
        "encoder_hidden_activation_sinusoidal_shift": "torch.nn.LeakyReLU(negative_slope=0.01)",

        "encoder_output_activation_D": "torch.nn.Identity()",
        "encoder_output_activation_phi": "torch.nn.Identity()",
        "encoder_output_activation_c": "torch.nn.Identity()",
        "encoder_output_activation_alpha": "torch.nn.Identity()",
        "encoder_output_activation_sinusoidal_shift": "torch.nn.Identity()",

        "EConv_mlp_hidden_activation": "torch.nn.LeakyReLU(negative_slope=0.01)",
        "EConv_mlp_output_activation": "torch.nn.Identity()",

        "output_mlp_hidden_activation": "torch.nn.LeakyReLU(negative_slope=0.01)",
        "output_mlp_output_activation": "torch.nn.Identity()"
    },

    "F_z_list": [64, 64, 64],
    "GAT_N_heads": 4,
    "EConv_bias": true,
    "GAT_bias": true,
    "encoder_biases": true,

    "chiral_message_passing": true,
    "CMP_EConv_MLP_hidden_sizes": [32],
    "CMP_GAT_N_heads": 2,

    "encoder_reduction": "sum",

    "output_concatenation_mode": "both"

}

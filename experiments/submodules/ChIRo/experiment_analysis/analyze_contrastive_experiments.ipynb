{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.nn.acts import swish\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import rdkit\n",
    "import rdkit.Chem\n",
    "from rdkit.Chem import TorsionFingerprints\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "import datetime\n",
    "import gzip\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from model.params_interpreter import string_to_object \n",
    "\n",
    "from model.alpha_encoder import Encoder\n",
    "\n",
    "from model.gnn_3D.schnet import SchNet\n",
    "from model.gnn_3D.dimenet_pp import DimeNetPlusPlus\n",
    "from model.gnn_3D.spherenet import SphereNet\n",
    "\n",
    "from model.train_functions import contrastive_loop_alpha\n",
    "from model.train_models import train_contrastive_model\n",
    "\n",
    "from model.gnn_3D.train_functions import contrastive_loop\n",
    "from model.gnn_3D.train_models import train_contrastive_model\n",
    "\n",
    "from model.datasets_samplers import Dataset_3D_GNN, MaskedGraphDataset, StereoBatchSampler, SiameseBatchSampler, Sample_Map_To_Positives, Sample_Map_To_Negatives, NegativeBatchSampler, SingleConformerBatchSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = pd.read_pickle('final_data_splits/test_contrastive_MOL_448017_89914_38659.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ChIRo_model(path_to_params_file = None, path_to_model_dict = None):\n",
    "    \n",
    "    with open(str(path_to_params_file)) as f: \n",
    "        params_model = json.load(f)\n",
    "    best_model_state = torch.load(str(path_to_model_dict), map_location=device)\n",
    "    \n",
    "    layers_dict = deepcopy(params_model['layers_dict'])\n",
    "    activation_dict = deepcopy(params_model['activation_dict'])\n",
    "    for key, value in params_model['activation_dict'].items(): \n",
    "        activation_dict[key] = string_to_object[value] # convert strings to actual python objects/functions using pre-defined mapping\n",
    "    \n",
    "    num_node_features = 52\n",
    "    num_edge_features = 14\n",
    "    \n",
    "    model = Encoder(\n",
    "        F_z_list = params_model['F_z_list'], # dimension of latent space\n",
    "        F_H = params_model['F_H'], # dimension of final node embeddings, after EConv and GAT layers\n",
    "        F_H_embed = num_node_features, # dimension of initial node feature vector, currently 41\n",
    "        F_E_embed = num_edge_features, # dimension of initial edge feature vector, currently 12\n",
    "        F_H_EConv = params_model['F_H_EConv'], # dimension of node embedding after EConv layer\n",
    "        layers_dict = layers_dict,\n",
    "        activation_dict = activation_dict,\n",
    "        GAT_N_heads = params_model['GAT_N_heads'],\n",
    "        chiral_message_passing = params_model['chiral_message_passing'],\n",
    "        CMP_EConv_MLP_hidden_sizes = params_model['CMP_EConv_MLP_hidden_sizes'],\n",
    "        CMP_GAT_N_layers = params_model['CMP_GAT_N_layers'],\n",
    "        CMP_GAT_N_heads = params_model['CMP_GAT_N_heads'],\n",
    "        c_coefficient_normalization = params_model['c_coefficient_normalization'], # None, or one of ['softmax']\n",
    "        sinusoidal_shift = params_model['sinusoidal_shift'], # true or false\n",
    "        encoder_reduction = params_model['encoder_reduction'], #mean or sum\n",
    "        output_concatenation_mode = params_model['output_concatenation_mode'], # none or 'contrastive' (if contrastive), conformer, molecule, or z_alpha (if regression)\n",
    "        EConv_bias = params_model['EConv_bias'], \n",
    "        GAT_bias = params_model['GAT_bias'], \n",
    "        encoder_biases = params_model['encoder_biases'], \n",
    "        dropout = params_model['dropout'], # applied to hidden layers (not input/output layer) of Encoder MLPs, hidden layers (not input/output layer) of EConv MLP, and all GAT layers (using their dropout parameter)\n",
    "        )\n",
    "    \n",
    "    model.load_state_dict(best_model_state, strict=True)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schnet_model(path_to_params_file = None, path_to_model_dict = None):\n",
    "    \n",
    "    with open(str(path_to_params_file)) as f: \n",
    "        params_schnet = json.load(f)\n",
    "    best_schnet_state = torch.load(str(path_to_model_dict), map_location=device)\n",
    "    \n",
    "    schnet = SchNet(hidden_channels = params_schnet['hidden_channels'], # 128\n",
    "               num_filters = params_schnet['num_filters'], # 128\n",
    "               num_interactions = params_schnet['num_interactions'], # 6\n",
    "               num_gaussians = params_schnet['num_gaussians'], # 50\n",
    "               cutoff = params_schnet['cutoff'], # 10.0\n",
    "               max_num_neighbors = params_schnet['max_num_neighbors'], # 32\n",
    "               out_channels = params_schnet['out_channels'], # 1\n",
    "               readout = 'add',\n",
    "               dipole = False,\n",
    "               mean = None,\n",
    "               std = None,\n",
    "               atomref = None, \n",
    "               MLP_hidden_sizes = [], # [] for contrastive\n",
    "    )\n",
    "    schnet.load_state_dict(best_schnet_state, strict=True)\n",
    "    schnet.to(device)\n",
    "    \n",
    "    return schnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dimenetpp_model(path_to_params_file = None, path_to_model_dict = None):\n",
    "    \n",
    "    with open(str(path_to_params_file)) as f: \n",
    "        params_dimenetpp = json.load(f)\n",
    "    best_dimenetpp_state = torch.load(str(path_to_model_dict), map_location=device)\n",
    "    \n",
    "    dimenetpp = DimeNetPlusPlus(\n",
    "            hidden_channels = params_dimenetpp['hidden_channels'], # 128\n",
    "            out_channels = params_dimenetpp['out_channels'], # 1\n",
    "            num_blocks = params_dimenetpp['num_blocks'], # 4\n",
    "            int_emb_size = params_dimenetpp['int_emb_size'], # 64\n",
    "            basis_emb_size = params_dimenetpp['basis_emb_size'], # 8\n",
    "            out_emb_channels = params_dimenetpp['out_emb_channels'], # 256\n",
    "            num_spherical = params_dimenetpp['num_spherical'], # 7\n",
    "            num_radial = params_dimenetpp['num_radial'], # 6\n",
    "            cutoff=params_dimenetpp['cutoff'], # 5.0\n",
    "            envelope_exponent=params_dimenetpp['envelope_exponent'], # 5\n",
    "            num_before_skip=params_dimenetpp['num_before_skip'], # 1\n",
    "            num_after_skip=params_dimenetpp['num_after_skip'], # 2\n",
    "            num_output_layers=params_dimenetpp['num_output_layers'], # 3\n",
    "            act=swish,\n",
    "            MLP_hidden_sizes = [], # [] for contrastive\n",
    "        )\n",
    "    \n",
    "    dimenetpp.load_state_dict(best_dimenetpp_state, strict=True)\n",
    "    dimenetpp.to(device)\n",
    "    \n",
    "    return dimenetpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spherenet_model(path_to_params_file = None, path_to_model_dict = None):\n",
    "    \n",
    "    with open(str(path_to_params_file)) as f: \n",
    "        params_spherenet = json.load(f)\n",
    "    best_spherenet_state = torch.load(str(path_to_model_dict), map_location=device)\n",
    "    \n",
    "    spherenet = SphereNet(\n",
    "                energy_and_force = False, # False\n",
    "                cutoff = params_spherenet['cutoff'], # 5.0\n",
    "                num_layers = params_spherenet['num_layers'], # 4\n",
    "                hidden_channels = params_spherenet['hidden_channels'], # 128\n",
    "                out_channels = params_spherenet['out_channels'], # 1\n",
    "                int_emb_size = params_spherenet['int_emb_size'], # 64\n",
    "                basis_emb_size_dist = params_spherenet['basis_emb_size_dist'], # 8\n",
    "                basis_emb_size_angle = params_spherenet['basis_emb_size_angle'], # 8\n",
    "                basis_emb_size_torsion = params_spherenet['basis_emb_size_torsion'], # 8\n",
    "                out_emb_channels = params_spherenet['out_emb_channels'], # 256\n",
    "                num_spherical = params_spherenet['num_spherical'], # 7\n",
    "                num_radial = params_spherenet['num_radial'], # 6\n",
    "                envelope_exponent = params_spherenet['envelope_exponent'], # 5\n",
    "                num_before_skip = params_spherenet['num_before_skip'], # 1\n",
    "                num_after_skip = params_spherenet['num_after_skip'], # 2\n",
    "                num_output_layers = params_spherenet['num_output_layers'], # 3\n",
    "                act=swish, \n",
    "                output_init='GlorotOrthogonal', \n",
    "                use_node_features = True,\n",
    "                MLP_hidden_sizes = [], # [] for contrastive\n",
    "        )\n",
    "    \n",
    "    spherenet.load_state_dict(best_spherenet_state, strict=True)\n",
    "    spherenet.to(device)\n",
    "    \n",
    "    return spherenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_atom_number(mol, label = 'atomNote'):\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom.SetProp(label, str(atom.GetIdx()))\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_bond(mol, dihedral = [1,2,3,4], rot = 0.0): # rot in radians\n",
    "    mol_rotated = deepcopy(mol)\n",
    "    angle = rdkit.Chem.rdMolTransforms.GetDihedralRad(mol_rotated.GetConformer(), dihedral[0], dihedral[1], dihedral[2], dihedral[3])\n",
    "    rdkit.Chem.rdMolTransforms.SetDihedralRad(mol_rotated.GetConformer(), dihedral[0], dihedral[1], dihedral[2], dihedral[3], angle + rot)\n",
    "    return mol_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect_mol(mol):\n",
    "    mol_reflected = deepcopy(mol)\n",
    "    for i in range(mol_reflected.GetNumAtoms()):\n",
    "        position = rdkit.Chem.rdchem.Conformer.GetAtomPosition(mol_reflected.GetConformer(), i)\n",
    "        position = list(position)\n",
    "        position[2] = position[2]*-1\n",
    "        rdkit.Chem.rdchem.Conformer.SetAtomPosition(mol_reflected.GetConformer(), i, position)\n",
    "    molblock = rdkit.Chem.MolToMolBlock(mol_reflected)\n",
    "    mol_reflected = rdkit.Chem.MolFromMolBlock(molblock)\n",
    "    return mol_reflected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing example conformers in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = 'CC(C)C(C)(Cc1nncn1C)C(=O)O'\n",
    "conformers_df = test_dataframe[(test_dataframe.SMILES_nostereo == smiles)].reset_index(drop = True)\n",
    "conformers = list(conformers_df.rdkit_mol_cistrans_stereo)\n",
    "IDs = list(conformers_df.ID)\n",
    "show_atom_number(conformers[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflecting each conformer across the xy plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflected_conformers = conformers + [reflect_mol(conf) for conf in conformers]\n",
    "reflected_df = pd.DataFrame()\n",
    "reflected_df['ID'] = [rdkit.Chem.MolToSmiles(conf) for conf in reflected_conformers]\n",
    "reflected_df['SMILES_nostereo'] = [smiles]*len(IDs) + [smiles]*len(IDs)\n",
    "reflected_df['rdkit_mol_cistrans_stereo'] = reflected_conformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotating bonds near the chiral center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotated_conformers(smile_IDs, conformers, dihedral, rotations):\n",
    "    rot_conformers = [deepcopy(c) for c in conformers]\n",
    "\n",
    "    all_conformers = []\n",
    "    all_IDs = []\n",
    "    for i, conf in enumerate(rot_conformers):\n",
    "        conformers_rotated = [rotate_bond(conf, dihedral = dihedral, rot = rot) for rot in rots]\n",
    "        smi = [smile_IDs[i]]*len(conformers_rotated)\n",
    "        all_conformers += conformers_rotated\n",
    "        all_IDs += smi\n",
    "    \n",
    "    rotated_df = pd.DataFrame()\n",
    "    rotated_df['ID'] = all_IDs\n",
    "    rotated_df['SMILES_nostereo'] = [smiles]*len(all_IDs)\n",
    "    rotated_df['rdkit_mol_cistrans_stereo'] = all_conformers\n",
    "    \n",
    "    return rotated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rots = np.arange(0, 360, 30) * (np.pi/180)\n",
    "\n",
    "torsion_1 = [12, 7, 5, 8]\n",
    "rotated_df_1 = get_rotated_conformers(smile_IDs = IDs, \n",
    "                                      conformers = conformers, \n",
    "                                      dihedral = torsion_1, \n",
    "                                      rotations = rots)\n",
    "\n",
    "torsion_2 = [0, 11, 5, 8]\n",
    "rotated_df_2 = get_rotated_conformers(smile_IDs = rotated_df_1['ID'], \n",
    "                                      conformers = list(rotated_df_1['rdkit_mol_cistrans_stereo']), \n",
    "                                      dihedral = torsion_2, \n",
    "                                      rotations = rots)\n",
    "\n",
    "torsion_3 = [0, 11, 5, 8]\n",
    "rotated_df_3 = get_rotated_conformers(smile_IDs = rotated_df_2['ID'], \n",
    "                                      conformers = list(rotated_df_2['rdkit_mol_cistrans_stereo']), \n",
    "                                      dihedral = torsion_3, \n",
    "                                      rotations = rots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ChIRo_latent_space(model, conformer_df):\n",
    "    \n",
    "    test_dataset_model = MaskedGraphDataset(conformer_df, \n",
    "                                    regression = '', #'', score, score_range_binary, relative_score_range_binary, RS_label_binary\n",
    "                                    stereoMask = True,\n",
    "                                    mask_coordinates = False, \n",
    "                                    )\n",
    "    test_loader_model = torch_geometric.data.DataLoader(test_dataset_model, shuffle = False, batch_size = 100)\n",
    "    \n",
    "    def get_local_structure_map(psi_indices):\n",
    "        LS_dict = OrderedDict()\n",
    "        LS_map = torch.zeros(psi_indices.shape[1], dtype = torch.long)\n",
    "        v = 0\n",
    "        for i, indices in enumerate(psi_indices.T):\n",
    "            tupl = (int(indices[1]), int(indices[2]))\n",
    "            if tupl not in LS_dict:\n",
    "                LS_dict[tupl] = v\n",
    "                v += 1\n",
    "            LS_map[i] = LS_dict[tupl]\n",
    "    \n",
    "        alpha_indices = torch.zeros((2, len(LS_dict)), dtype = torch.long)\n",
    "        for i, tupl in enumerate(LS_dict):\n",
    "            alpha_indices[:,i] = torch.LongTensor(tupl)\n",
    "    \n",
    "        return LS_map, alpha_indices\n",
    "    \n",
    "    latent_space = torch.zeros((len(test_dataset_model), 2))\n",
    "    start = 0\n",
    "    for batch_data in tqdm(test_loader_model):    \n",
    "        psi_indices = batch_data.dihedral_angle_index\n",
    "        LS_map, alpha_indices = get_local_structure_map(psi_indices)\n",
    "    \n",
    "        batch_data = batch_data.to(device)\n",
    "        LS_map = LS_map.to(device)\n",
    "        alpha_indices = alpha_indices.to(device)\n",
    "    \n",
    "        latent_vector, phase_shift_norm, z_alpha, mol_embedding, c_tensor, phase_cos, phase_sin, sin_cos_psi, sin_cos_alpha = model(batch_data, LS_map, alpha_indices)\n",
    "        \n",
    "        latent_vector = latent_vector[:, latent_vector.shape[1]//3 * 2 :]\n",
    "        latent_space[start:start + latent_vector.shape[0]] = latent_vector\n",
    "        start += latent_vector.shape[0]\n",
    "    \n",
    "    return latent_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3D_GNN_latent_space(model, conformer_df):\n",
    "    test_dataset_3D_GNN = Dataset_3D_GNN(conformer_df, \n",
    "                                    regression = '',\n",
    "                              )\n",
    "    test_loader_3D_GNN = torch_geometric.data.DataLoader(test_dataset_3D_GNN, shuffle = False, batch_size = 100)\n",
    "    \n",
    "    latent_space = torch.zeros((len(test_dataset_3D_GNN), 2))\n",
    "\n",
    "    start = 0\n",
    "    for batch_data in tqdm(test_loader_3D_GNN):\n",
    "        batch_data = batch_data.to(device)\n",
    "        \n",
    "        node_batch = deepcopy(batch_data.batch)\n",
    "        z = deepcopy(batch_data.x)\n",
    "        pos = deepcopy(batch_data.pos)\n",
    "        \n",
    "        try:\n",
    "            latent_vector = model(z.squeeze(), pos, node_batch)\n",
    "        except Exception as e:\n",
    "            print('3D GNN failed to process batch: ', start)\n",
    "            print(e)\n",
    "            latent_vector = torch.zeros((int(max(node_batch.squeeze().detach().numpy())), 2))\n",
    "        \n",
    "        latent_space[start:start + latent_vector.shape[0]] = latent_vector.detach().cpu()\n",
    "        \n",
    "        start += latent_vector.shape[0]\n",
    "    \n",
    "    return latent_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model, compute latent vectors for each conformer in specified dataframe, and plot latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiro = get_ChIRo_model(path_to_params_file = 'paper_results/contrastive_experiment/ChIRo/params_contrastive_ChIRo.json', \n",
    "                        path_to_model_dict = 'paper_results/contrastive_experiment/ChIRo/best_model.pt')\n",
    "\n",
    "plot_df = reflected_df\n",
    "\n",
    "latent_space = get_ChIRo_latent_space(chiro, plot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "cmap = matplotlib.cm.bwr(np.linspace(0.,1,40,))\n",
    "cmap = matplotlib.colors.ListedColormap(cmap[2:,:-1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = [4, 4])\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(plot_df.ID) \n",
    "\n",
    "plot = ax.scatter(latent_space[:, 0], latent_space[:, 1], c = labels, cmap=cmap, s = 400, alpha = 0.5, edgecolors = 'black')\n",
    "\n",
    "ax.ticklabel_format(scilimits = (-1, 1))\n",
    "fig.tight_layout(pad = 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-chiral_gnn]",
   "language": "python",
   "name": "conda-env-.conda-chiral_gnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
